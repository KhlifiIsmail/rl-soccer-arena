# Training Configuration for RL Soccer Arena

# Environment Configuration
env:
  max_episode_steps: 2000
  time_step: 0.02  # 50 Hz for 2D kinematics
  mode: "2d"  # "2d" for kinematic env, "3d" for PyBullet
  reward_goal_scored: 10.0
  reward_goal_conceded: -10.0
  reward_ball_proximity_scale: 0.01
  reward_time_penalty: -0.001
  reward_ball_progress_scale: 0.05
  reward_possession_bonus: 0.05
  possession_distance_threshold: 1.5

# Model Configuration (PPO)
model:
  learning_rate: 0.0003
  n_steps: 2048
  batch_size: 64
  n_epochs: 10
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.01
  vf_coef: 0.5
  max_grad_norm: 0.5
  device: "auto"  # "auto", "cpu", or "cuda"

# Training Configuration
training:
  total_timesteps: 1000000
  n_envs: 4
  use_subprocess: false
  log_freq: 1000
  save_freq: 10000
  use_early_stopping: false
  early_stopping_patience: 10
  early_stopping_check_freq: 10000

# Self-Play Configuration
self_play:
  enabled: true
  pool_size: 10
  save_freq: 100000
  update_freq: 10000
  selection_strategy: "uniform"  # "latest", "random", "uniform"

# General Settings
seed: 42
output_dir: "outputs"
